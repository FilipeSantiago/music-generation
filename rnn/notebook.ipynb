{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mido import MidiFile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "from music21 import converter, instrument, note, chord, stream\n",
    "import pypianoroll\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"/home/skynet/research/music-generation/pre-processing\")\n",
    "\n",
    "from note_representation import NoteRepresentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/home/skynet/data/music-generation'\n",
    "data_dir = root_dir + '/Lakh Piano Dataset/lpd_5/lpd_5_cleansed'\n",
    "midi_dir = f'{root_dir}/Lakh Piano Dataset/lpd_5_midi'\n",
    "lakh_dir = f'{root_dir}/Lakh Piano Dataset/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "note_rep = NoteRepresentation(midi_dir)\n",
    "net_in, net_out = note_rep.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "note_to_int = note_rep.note_to_int\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import random\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a random observation from the network input, return (input, target), each shifted by 1\n",
    "# NOT NEEDED ANYMORE - each epoch just using entire dataset\n",
    "def random_training_set(network_input):    \n",
    "    chunk = network_input[random.randint(0, network_input.shape[0] - 1), : , :]\n",
    "    input = torch.tensor(chunk[:-1], dtype = torch.long).squeeze()\n",
    "    target = torch.tensor(chunk[1:], dtype = torch.long).squeeze()\n",
    "    return input, target\n",
    "\n",
    "\n",
    "def grad_clipping(net, theta):  \n",
    "    \"\"\"Clip the gradient.\"\"\"\n",
    "    params = [p for p in net.parameters() if p.requires_grad]\n",
    "\n",
    "    norm = torch.sqrt(sum(torch.sum((p.grad ** 2)) for p in params))\n",
    "    \n",
    "    if norm > theta:\n",
    "        for param in params:\n",
    "            param.grad[:] *= theta / norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerationRNN(nn.Module):\n",
    "  # input_size: number of possible pitches\n",
    "  # hidden_size: embedding size of each pitch\n",
    "  # output_size: number of possible pitches (probability distribution)\n",
    "    def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n",
    "        super(GenerationRNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers)\n",
    "        self.decoder = nn.Linear(hidden_size * n_layers, output_size)\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        # Creates embedding of the input texts\n",
    "        #print('initial input', input.size())\n",
    "        input = self.embedding(input.view(1, -1))\n",
    "        #print('input after embedding', input.size())\n",
    "        output, hidden = self.gru(input, hidden)\n",
    "        #print('output after gru', output.size())\n",
    "        #print('hidden after gru', hidden.size())\n",
    "        output = self.decoder(hidden.view(1, -1))\n",
    "        #print('output after decoder', output.size())\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(self.n_layers, 1, self.hidden_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single training step for ONE sequence\n",
    "def train_sequence(input, target, model, optimizer, criterion):\n",
    "    # Initialize hidden state, zero the gradients of model \n",
    "    hidden = model.init_hidden()\n",
    "    model.zero_grad()\n",
    "    loss = 0\n",
    "    # For each character in our chunk (except last), compute the hidden and ouput\n",
    "    # Using each output, compute the loss with the corresponding target \n",
    "    for i in range(len(input)):\n",
    "        output, hidden = model(input[i], hidden)\n",
    "        loss += criterion(output, target[i].unsqueeze(0))\n",
    "    \n",
    "    # Backpropagate, clip gradient and optimize\n",
    "    loss.backward()\n",
    "    grad_clipping(model, 1)\n",
    "    optimizer.step()\n",
    "\n",
    "    # Return average loss for the input sequence\n",
    "    return loss.data.item() / len(input)\n",
    "\n",
    "def test_sequence(input, target, model, criterion):\n",
    "    # Initialize hidden state, zero the gradients of model \n",
    "    hidden = model.init_hidden()\n",
    "    model.zero_grad()\n",
    "    loss = 0\n",
    "    # For each character in our chunk (except last), compute the hidden and ouput\n",
    "    # Using each output, compute the loss with the corresponding target \n",
    "    for i in range(len(input)):\n",
    "        output, hidden = model(input[i], hidden)\n",
    "        loss += criterion(output, target[i].unsqueeze(0))\n",
    "\n",
    "    # Return average loss for the input sequence\n",
    "    return loss.data.item() / len(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall training loop\n",
    "def training_loop(model, optimizer, scheduler, criterion, train_input, test_input):\n",
    "\n",
    "  train_losses = []\n",
    "  test_losses = []\n",
    "\n",
    "  for epoch in range(1, n_epochs + 1):\n",
    "    running_loss = 0\n",
    "    model.train()\n",
    "\n",
    "    # Training - sample 2000\n",
    "    sampled_train_ids = random.choices(range(train_input.shape[0]), k = 2000)\n",
    "    print(scheduler.get_last_lr())\n",
    "    for i in range(train_input.shape[0]):\n",
    "      sequence = train_input[i, : , :]\n",
    "      input = torch.tensor(sequence[:-1], dtype = torch.long).squeeze().to(device)\n",
    "      target = torch.tensor(sequence[1:], dtype = torch.long).squeeze().to(device)\n",
    "      loss = train_sequence(input, target, model, optimizer, criterion)\n",
    "      running_loss += loss\n",
    "\n",
    "    train_epoch_loss = running_loss / 2000\n",
    "    train_losses.append(train_epoch_loss)\n",
    "    scheduler.step()\n",
    "\n",
    "    running_loss = 0\n",
    "    # model.eval()\n",
    "    # # Testing\n",
    "    # for i in range(test_input.shape[0]):\n",
    "    #   sequence = test_input[i, : , :]\n",
    "    #   input = torch.tensor(sequence[:-1], dtype = torch.long).squeeze().to(device)\n",
    "    #   target = torch.tensor(sequence[1:], dtype = torch.long).squeeze().to(device)\n",
    "    #   loss = test_sequence(input, target, model, criterion)\n",
    "    #   running_loss += loss\n",
    "\n",
    "    # test_epoch_loss = running_loss / 1000\n",
    "    # test_losses.append(test_epoch_loss)\n",
    "    test_epoch_loss = 0\n",
    "\n",
    "    print('Epoch {}, Train Loss: {}, Test Loss: {}, Time: {}'.format(epoch, train_epoch_loss, test_epoch_loss, datetime.now()))\n",
    "\n",
    "  return train_losses, test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.002]\n",
      "Epoch 1, Train Loss: 2.366385728668786, Test Loss: 0, Time: 2023-04-02 16:57:05.041006\n",
      "[0.00198]\n",
      "Epoch 2, Train Loss: 1.8761272995558023, Test Loss: 0, Time: 2023-04-02 16:57:56.753868\n",
      "[0.0019602]\n",
      "Epoch 3, Train Loss: 1.6099545242245414, Test Loss: 0, Time: 2023-04-02 16:58:22.955195\n",
      "[0.0019405980000000002]\n",
      "Epoch 4, Train Loss: 1.4200630006631214, Test Loss: 0, Time: 2023-04-02 16:59:02.216330\n",
      "[0.0019211920199999999]\n",
      "Epoch 5, Train Loss: 1.2661156891129022, Test Loss: 0, Time: 2023-04-02 16:59:26.245750\n",
      "[0.0019019800997999998]\n",
      "Epoch 6, Train Loss: 1.1523321756714335, Test Loss: 0, Time: 2023-04-02 17:00:11.057461\n",
      "[0.001882960298802]\n",
      "Epoch 7, Train Loss: 1.0555116254273116, Test Loss: 0, Time: 2023-04-02 17:00:49.316427\n",
      "[0.0018641306958139799]\n",
      "Epoch 8, Train Loss: 0.9782372354767294, Test Loss: 0, Time: 2023-04-02 17:01:24.296086\n",
      "[0.0018454893888558402]\n"
     ]
    }
   ],
   "source": [
    "n_pitches = len(note_to_int)\n",
    "hidden_size = 96\n",
    "n_layers = 2\n",
    "n_epochs = 40\n",
    "lr = 0.002\n",
    "lr_lambda = 0.99\n",
    "\n",
    "model = GenerationRNN(input_size = n_pitches, hidden_size = hidden_size, output_size = n_pitches, n_layers = n_layers).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda = lambda epoch: lr_lambda ** epoch)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "train_losses, test_losses = training_loop(model, optimizer, scheduler, criterion, net_in, net_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b2072615460adb9797907d4ec26f4e556c556fb3ff0cffdd51046a2ee6ceba4b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
